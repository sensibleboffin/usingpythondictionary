{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ba21ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np; # Mostly used for array manipulation datatype numpy.ndarray\n",
    "from sklearn.linear_model import LinearRegression # Used for implementing Logistic regression\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt # Plotting in python3 using Matplotlib library\n",
    "import math # math module for exp function; For e value\n",
    "# generate random integer values\n",
    "from numpy.random import seed\n",
    "from numpy.random import randint\n",
    "import array\n",
    "# seed random number generator\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560b5cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_shapes(num_oflayers,nodes_eachlayer,rows,cols,eachlayer,shape_wts,shape_b):\n",
    "    for eachlayer in range(num_oflayers):\n",
    "        ## shape of weights in given current layer is nodesinpreviouslayer X nodesincurrentlayer\n",
    "        if(eachlayer == 0):\n",
    "            shape_forwt = (cols,nodes_eachlayer[1])\n",
    "            shape_wts[str(eachlayer)] = shape_forwt\n",
    "            \n",
    "            shape_forb = rows\n",
    "            shape_b[str(eachlayer)] = shape_forb \n",
    "        else:\n",
    "            shape_forwt = (nodes_eachlayer[eachlayer-1],nodes_eachlayer[eachlayer])\n",
    "            shape_wts[str(eachlayer)] = shape_forwt\n",
    "                        \n",
    "            shape_forb = rows\n",
    "            shape_b[str(eachlayer)] = shape_forb\n",
    "    \n",
    "    \n",
    "    return shape_wts,shape_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c6a1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_reg(features,weights,b):\n",
    "    lin_reg_output = np.dot(features,weights)+b\n",
    "    print(\"shape of input activations:\",np.shape(features))\n",
    "    print(\"shape of weights:\",np.shape(weights))\n",
    "    print(\"shape of b:\",np.shape(b))\n",
    "    print(\"shape of lin reg output:\",np.shape(lin_reg_output))\n",
    "\n",
    "    return lin_reg_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e98a4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_reg(lin_reg_output):\n",
    "    log_reg_output = 1/(1+np.exp(-lin_reg_output))\n",
    "    print(\"shape of logistic reg output:\",np.shape(log_reg_output))\n",
    "\n",
    "    return log_reg_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c4575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_procedure(lin_reg_output):\n",
    "    #calculate ReLU g(lin_reg or z) = max(0,z) when z>=0 and g(z)=0 when z<0\n",
    "    print(\"linear regression output:\",lin_reg_output)\n",
    "    relu_val = lin_reg_output\n",
    "    relu_val[relu_val<0]=0\n",
    "    relu_output = relu_val\n",
    "    print(\"shape of ReLU output:\",np.shape(relu_output))\n",
    "\n",
    "    return relu_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a0f39b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b25ea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "       \n",
    "    # Input feature 1 patient age\n",
    "    # Input feature 2 tumor size\n",
    "    # Input feature 3 family history (y/n:0/1)\n",
    "    # Input feature 4 regular junk food intake\n",
    "    # Input feature 5 currently smoking\n",
    "    # Input feature 6 stressful lifestyle\n",
    "    # Input feature 7 working with chemicals\n",
    "    # Input feature 8 urban/rural (0/1)\n",
    "    # Input feature 9 sleep duration (1hr-10hrs)\n",
    "    # Input feature 10 regular exercise\n",
    "    \n",
    "    num_ofpatients = 398\n",
    "    pat_age = randint(0,100,num_ofpatients)\n",
    "    tum_size = randint(1,10,num_ofpatients) # in cm\n",
    "    fm_histry = randint(0,2,num_ofpatients)\n",
    "    junk_food = randint(0,2,num_ofpatients)\n",
    "    smoking = randint(0,2,num_ofpatients)\n",
    "    stress_lif = randint(0,2,num_ofpatients)\n",
    "    work_withchem = randint(0,2,num_ofpatients)\n",
    "    rural_urbn = randint(0,2,num_ofpatients)\n",
    "    sleep_dur = randint(1,10,num_ofpatients)\n",
    "    reg_exerc = randint(0,2,num_ofpatients)\n",
    "    features = np.transpose([pat_age, tum_size, fm_histry, junk_food,smoking,stress_lif,work_withchem,rural_urbn,sleep_dur,reg_exerc]);\n",
    "    [rows,cols] = np.shape(features)\n",
    "    \n",
    "    # Output benign or malignant 0/1\n",
    "    diagnosis_res = randint(0,2,num_ofpatients)\n",
    "    \n",
    "    \n",
    "        \n",
    "    print(\"Enter number of layers:\")\n",
    "    num_oflayers = int(input())\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #### Prepare each layer with desired number of nodes ######\n",
    "    \n",
    "    nodes_eachlayer = np.empty([num_oflayers],dtype=int)\n",
    "    \n",
    "    \n",
    "    for eachlayer in range(num_oflayers):\n",
    "       \n",
    "        if(eachlayer == 0):\n",
    "            nodes_eachlayer[eachlayer] = cols\n",
    "        else:\n",
    "            print(\"Enter num of nodes for layer no:\", eachlayer)\n",
    "            nodes_eachlayer[eachlayer] = int(input())\n",
    "    #print(nodes_eachlayer)\n",
    "    \n",
    "    \n",
    "        \n",
    "    ######## Prepare shapes of weights and bias per each layer #########\n",
    "    weights = {}\n",
    "    b = {}\n",
    "    shape_wts = {}\n",
    "    shape_b = {}\n",
    "    shape_wts, shape_b = prepare_shapes(num_oflayers,nodes_eachlayer,rows,cols,eachlayer,shape_wts,shape_b)\n",
    "    \n",
    "    print(\"weight shapes dictionary\",shape_wts)\n",
    "    print(\"b shapes dictionary\",shape_b)\n",
    "    \n",
    "    \n",
    "    ############# No ambiguity w.r.t shapes of weights and bias for each layer ###\n",
    "    \n",
    "    dj_dw = {}\n",
    "    dj_db = {}\n",
    "    error = np.zeros(rows,dtype = np.float64)\n",
    "    lossfunction = np.zeros(rows,dtype = np.float64)\n",
    "    Jcostfunctionold = 0.00\n",
    "    \n",
    "    \n",
    "    max_iterations = 2\n",
    "    learningratew = 1e-4\n",
    "    learningrateb = 1e-7\n",
    "       \n",
    "    \n",
    "    print(\"Input features dim:\",np.shape(features))\n",
    "    \n",
    "    # initialize weights and b before running ANN, which go into 1st epoch of the ANN\n",
    "    \n",
    "    for eachlayer in range(num_oflayers):\n",
    "        # [numofnodespreviouslayer,numofnodescurrlayer] = \n",
    "        numofnodespreviouslayer = shape_wts[str(eachlayer)][0]\n",
    "        numofnodescurrlayer = shape_wts[str(eachlayer)][1]\n",
    "        weights[str(eachlayer)] = randint(1,10,size = (numofnodespreviouslayer,numofnodescurrlayer))  # np.zeros(shape_wts[str(eachlayer)],dtype=np.float64) \n",
    "        b[str(eachlayer)] = randint(1,100,size = shape_b[str(eachlayer)]).reshape(rows,1) # np.zeros(shape_b[str(eachlayer)],dtype=np.float64) \n",
    "        \n",
    "        dj_dw[str(eachlayer)] = np.zeros(shape_wts[str(eachlayer)][0],dtype=np.float64)\n",
    "        dj_db[str(eachlayer)] = np.zeros(shape_b[str(eachlayer)],dtype=np.float64)\n",
    "        \n",
    "        \n",
    "    ###### Finish initialization of weights, b for epoch 0\n",
    "    \n",
    "    #print(\"Initialized weights\",weights)\n",
    "    #print(\"Initialized b\",b)\n",
    "    \n",
    "    \n",
    "    for eachepoch in range(max_iterations):\n",
    "        print(\"Epoch No:\",eachepoch)\n",
    "        for eachlayer in range(num_oflayers):\n",
    "            if(eachlayer == 0):\n",
    "                inputs_activations = features\n",
    "            \n",
    "            else:\n",
    "                print(\"layer no:\",eachlayer)\n",
    "                ## Since this is a single hidden layer ANN, only (Hidden) (index:layer 1)\n",
    "                # Linear OR logistic OR softmax OR ReLU is done\n",
    "                lin_reg_output = lin_reg(inputs_activations,weights[str(eachlayer)],b[str(eachlayer)])\n",
    "                log_reg_output = logistic_reg(lin_reg_output)\n",
    "                relu_output = relu_procedure(lin_reg_output)\n",
    "                inputs_activations = lin_reg_output\n",
    "                #softmax_output = softmax_reg()\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b8a370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
